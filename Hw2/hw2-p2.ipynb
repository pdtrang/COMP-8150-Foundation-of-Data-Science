{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction using Naive Bayes:  [0 0 0 0]\n",
      "Precision:  [ 1.  1.  1.  1.  1.]\n",
      "Precision mean +/- std:  1.0 +/- 0.0\n",
      "Recall:  [ 0.2   0.19  0.11  0.13  0.13]\n",
      "Recall mean +/- std:  0.152 +/- 0.036\n",
      "F1-scores:  [ 0.76251973  0.75834799  0.72295465  0.73157003  0.73157003]\n",
      "F1-scores mean +/- std:  0.741392486216 +/- 0.0159170604899\n",
      "\n",
      "Logistic Regression with L2\n",
      "Prediction using L2 regularization with C=1.0:  [1 1 0 0]\n",
      "Precision:  [ 1.          1.          1.          0.98701299  1.        ]\n",
      "Precision mean +/- std:  0.997402597403 +/- 0.00519480519481\n",
      "Recall:  [ 0.92  0.77  0.72  0.76  0.85]\n",
      "Recall mean +/- std:  0.804 +/- 0.0717216843082\n",
      "F1-scores:  [ 0.98116263  0.94406446  0.93106507  0.93906196  0.96408967]\n",
      "F1-scores mean +/- std:  0.951888758819 +/- 0.0182493522223\n",
      "Prediction using L2 regularization with C=0.5:  [1 1 0 0]\n",
      "Precision:  [ 1.  1.  1.  1.  1.]\n",
      "Precision mean +/- std:  1.0 +/- 0.0\n",
      "Recall:  [ 0.78  0.56  0.51  0.56  0.64]\n",
      "Recall mean +/- std:  0.61 +/- 0.0946572765296\n",
      "F1-scores:  [ 0.94662239  0.886696    0.87178222  0.88644156  0.90925538]\n",
      "F1-scores mean +/- std:  0.900159511254 +/- 0.0261390631748\n",
      "\n",
      "Logistic Regression with L1\n",
      "Prediction using L1 regularization with C=1.0:  [1 1 0 0]\n",
      "Precision:  [ 0.79032258  0.98924731  0.77884615  0.96428571  1.        ]\n",
      "Precision mean +/- std:  0.904540352121 +/- 0.0986935180212\n",
      "Recall:  [ 0.98  0.92  0.81  0.81  0.87]\n",
      "Recall mean +/- std:  0.878 +/- 0.0655438784327\n",
      "F1-scores:  [ 0.93729317  0.97884889  0.90567051  0.94721822  0.96900857]\n",
      "F1-scores mean +/- std:  0.947607870278 +/- 0.0256876585927\n",
      "Prediction using L1 regularization with C=0.5:  [1 1 0 0]\n",
      "Precision:  [ 0.83809524  0.9875      0.81818182  0.95522388  0.9875    ]\n",
      "Precision mean +/- std:  0.917300187375 +/- 0.0740163616975\n",
      "Recall:  [ 0.88  0.79  0.72  0.64  0.79]\n",
      "Recall mean +/- std:  0.764 +/- 0.0801498596381\n",
      "F1-scores:  [ 0.93327914  0.94686858  0.8955625   0.90250065  0.94674723]\n",
      "F1-scores mean +/- std:  0.92499161765 +/- 0.0218746792273\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes for spam filtering\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import linear_model\n",
    "\n",
    "flist = os.listdir(\"spamassasin\\\\processed_ham\")\n",
    "data = []\n",
    "target = []\n",
    "index = []\n",
    "rows = []\n",
    "for f in flist:\n",
    "    ifile=open(\"spamassasin\\\\processed_ham\\\\\"+f)\n",
    "    text = \"\"\n",
    "    lines = ifile.readlines()\n",
    "    for l in lines:\n",
    "        text = text + l\n",
    "    ifile.close()\n",
    "    rows.append({'text': text, 'class': 0})\n",
    "    index.append(f)\n",
    "    data.append(text)\n",
    "    target.append(\"ham\")\n",
    "flist = os.listdir(\"spamassasin\\\\processed_spam\")\n",
    "\n",
    "for f in flist:\n",
    "    ifile=open(\"spamassasin\\\\processed_spam\\\\\"+f,encoding=\"ISO-8859-1\")\n",
    "    text = \"\"\n",
    "    lines = ifile.readlines()\n",
    "    for l in lines:\n",
    "        text = text + l\n",
    "    ifile.close()\n",
    "    rows.append({'text': text, 'class': 1})\n",
    "    index.append(f)\n",
    "    data.append(text)\n",
    "    target.append(\"spam\")\n",
    "\n",
    "# print (rows)\n",
    "data_frame = pd.DataFrame(rows, index=index)\n",
    "# print (data_frame)\n",
    "count_vectorizer = CountVectorizer()\n",
    "counts = count_vectorizer.fit_transform(data_frame['text'])\n",
    "transformer = TfidfTransformer()\n",
    "tfidf = transformer.fit_transform(counts)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "targets = data_frame['class'].values\n",
    "classifier.fit(tfidf, targets)\n",
    "\n",
    "examples = ['Buy one get one free', \"Want to make money\", \"Which one is a good phone?\", \"Phone on sale\"]\n",
    "\n",
    "example_counts = count_vectorizer.transform(examples)\n",
    "predictions = classifier.predict(example_counts)\n",
    "print (\"Prediction using Naive Bayes: \", predictions)\n",
    "\n",
    "NB_precision = cross_val_score(classifier, tfidf, targets, cv=5, scoring='precision')\n",
    "print (\"Precision: \", NB_precision)\n",
    "print (\"Precision mean +/- std: \", NB_precision.mean(), \"+/-\",NB_precision.std())\n",
    "\n",
    "NB_recall = cross_val_score(classifier, tfidf, targets, cv=5, scoring='recall')\n",
    "print (\"Recall: \", NB_recall)\n",
    "print (\"Recall mean +/- std: \", NB_recall.mean(), \"+/-\",NB_recall.std())\n",
    "\n",
    "NB_f1 = cross_val_score(classifier, tfidf, targets, cv=5, scoring='f1_weighted')\n",
    "print (\"F1-scores: \", NB_f1)\n",
    "print (\"F1-scores mean +/- std: \", NB_f1.mean(), \"+/-\",NB_f1.std())\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "print (\"\\nLogistic Regression with L2\")\n",
    "clf2 = linear_model.LogisticRegression(penalty='l2',C=1.0)\n",
    "clf2.fit(tfidf,targets)\n",
    "print(\"Prediction using L2 regularization with C=1.0: \",clf2.predict(example_counts))\n",
    "\n",
    "L2_precision = cross_val_score(clf2, tfidf, targets, cv=5, scoring='precision')\n",
    "print (\"Precision: \", L2_precision)\n",
    "print (\"Precision mean +/- std: \", L2_precision.mean(), \"+/-\",L2_precision.std())\n",
    "\n",
    "L2_recall = cross_val_score(clf2, tfidf, targets, cv=5, scoring='recall')\n",
    "print (\"Recall: \", L2_recall)\n",
    "print (\"Recall mean +/- std: \", L2_recall.mean(), \"+/-\",L2_recall.std())\n",
    "\n",
    "L2_f1 = cross_val_score(clf2, tfidf, targets, cv=5, scoring='f1_weighted')\n",
    "print (\"F1-scores: \", L2_f1)\n",
    "print (\"F1-scores mean +/- std: \", L2_f1.mean(), \"+/-\",L2_f1.std())\n",
    "\n",
    "\n",
    "clf2_1 = linear_model.LogisticRegression(penalty='l2',C=0.5)\n",
    "clf2_1.fit(tfidf,targets)\n",
    "print (\"Prediction using L2 regularization with C=0.5: \",clf2_1.predict(example_counts))\n",
    "\n",
    "L2_precision = cross_val_score(clf2_1, tfidf, targets, cv=5, scoring='precision')\n",
    "print (\"Precision: \", L2_precision)\n",
    "print (\"Precision mean +/- std: \", L2_precision.mean(), \"+/-\",L2_precision.std())\n",
    "\n",
    "L2_recall = cross_val_score(clf2_1, tfidf, targets, cv=5, scoring='recall')\n",
    "print (\"Recall: \", L2_recall)\n",
    "print (\"Recall mean +/- std: \", L2_recall.mean(), \"+/-\",L2_recall.std())\n",
    "\n",
    "\n",
    "L2_f1 = cross_val_score(clf2_1, tfidf, targets, cv=5, scoring='f1_weighted')\n",
    "print (\"F1-scores: \", L2_f1)\n",
    "print (\"F1-scores mean +/- std: \", L2_f1.mean(), \"+/-\",L2_f1.std())\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "print (\"\\nLogistic Regression with L1\")\n",
    "clf1 = linear_model.LogisticRegression(penalty='l1', C=1.0)\n",
    "clf1.fit(tfidf,targets)\n",
    "print (\"Prediction using L1 regularization with C=1.0: \",clf1.predict(example_counts))\n",
    "\n",
    "L1_precision = cross_val_score(clf1, tfidf, targets, cv=5, scoring='precision')\n",
    "print (\"Precision: \", L1_precision)\n",
    "print (\"Precision mean +/- std: \", L1_precision.mean(), \"+/-\",L1_precision.std())\n",
    "\n",
    "\n",
    "L1_recall = cross_val_score(clf1, tfidf, targets, cv=5, scoring='recall')\n",
    "print (\"Recall: \", L1_recall)\n",
    "print (\"Recall mean +/- std: \", L1_recall.mean(), \"+/-\",L1_recall.std())\n",
    "\n",
    "\n",
    "L1_f1 = cross_val_score(clf1, tfidf, targets, cv=5, scoring='f1_weighted')\n",
    "print (\"F1-scores: \", L1_f1)\n",
    "print (\"F1-scores mean +/- std: \", L1_f1.mean(), \"+/-\",L1_f1.std())\n",
    "\n",
    "clf1_1 = linear_model.LogisticRegression(penalty='l1', C=0.5)\n",
    "clf1_1.fit(tfidf,targets)\n",
    "print (\"Prediction using L1 regularization with C=0.5: \",clf1_1.predict(example_counts))\n",
    "\n",
    "L1_precision = cross_val_score(clf1_1, tfidf, targets, cv=5, scoring='precision')\n",
    "print (\"Precision: \", L1_precision)\n",
    "print (\"Precision mean +/- std: \", L1_precision.mean(), \"+/-\",L1_precision.std())\n",
    "\n",
    "L1_recall = cross_val_score(clf1_1, tfidf, targets, cv=5, scoring='recall')\n",
    "print (\"Recall: \", L1_recall)\n",
    "print (\"Recall mean +/- std: \", L1_recall.mean(), \"+/-\",L1_recall.std())\n",
    "\n",
    "\n",
    "L1_f1 = cross_val_score(clf1_1, tfidf, targets, cv=5, scoring='f1_weighted')\n",
    "print (\"F1-scores: \", L1_f1)\n",
    "print (\"F1-scores mean +/- std: \", L1_f1.mean(), \"+/-\",L1_f1.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
